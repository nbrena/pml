{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "005.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4cKNhhEWlIS"
      },
      "source": [
        "## Supervised Learning - Regression\n",
        "\n",
        "*y* is a real number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2ypw8OZ1WlIS",
        "outputId": "da0d08cd-cac8-4419-b74a-4524c97cdbd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn import linear_model\n",
        "'''\n",
        "+--------------+\n",
        "| frev         |\n",
        "+--------------+\n",
        "| x1 | x2 | y  |\n",
        "+----+----+----+\n",
        "| 2  | 3  | 4  |\n",
        "+----+----+----+\n",
        "| 8  | 5  | 9  |\n",
        "+----+----+----+\n",
        "| 6  | 4  | 7  |\n",
        "+----+----+----+\n",
        "| 10 | 2  | 7  |\n",
        "+----+----+----+\n",
        "| 4  | 2  | 4  |\n",
        "+----+----+----+\n",
        "| 16 | 7  | 15 |\n",
        "+----+----+----+\n",
        "'''\n",
        "model = linear_model.LinearRegression()\n",
        "\n",
        "#TBD: Fit/Train the model from observed data\n",
        "X = [[2,3],[8,5],[6,4],[10,2],[4,2]]\n",
        "Y = [4,9,7,7,4]\n",
        "reg = model.fit(X,Y)\n",
        "print(reg.coef_)\n",
        "\n",
        "#TBD: Use fitted/trained model to predict for any given x1, x2\n",
        "model.predict([[4,5]])\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5 1. ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDwvza35WlIS"
      },
      "source": [
        "## Supervised Learning - Classification\n",
        "*y* is a class/category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esSDeEnvWlIS",
        "outputId": "5e9d7b37-2642-4aac-e416-1e76b7a4453a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model.logistic import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "'''\n",
        "Building a labelled dataset of documents\n",
        "'''\n",
        "doc0 = \"hello world\"\n",
        "doc1 = \"foo bar\"\n",
        "doc2 = \"lottery prize winner\"\n",
        "docs_train = [doc0] * 1000 + [doc1] * 1000 + [doc2] * 400 \n",
        "\n",
        "docs_test = [\n",
        "             \"lottery winner\",\n",
        "             \"hello foo\", \n",
        "             \"hello bar\", \n",
        "             \"lottery prize\", \n",
        "             \"world foo\",\n",
        "             \"prize winner\",\n",
        "            ]\n",
        "\n",
        "'''\n",
        "    Converting documents to feature vectors\n",
        "'''\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(docs_train).toarray()\n",
        "features = vectorizer.get_feature_names()\n",
        "print(f'Features: {features}')\n",
        "Y_train = np.array([[0] * 100 + [0] * 100 + [1.0] * 4]).reshape(204,)\n",
        "#X_test = vectorizer.transform(docs_test).toarray(docs_test)\n",
        "\n",
        "'''\n",
        "Choosing the model\n",
        "'''\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "\n",
        "'''\n",
        "    Train the model\n",
        "'''\n",
        "#TBD Fit the model to training data\n",
        "classifier.fit(X_train, Y_train)\n",
        "'''\n",
        "    Test the model\n",
        "'''\n",
        "#TBD Use fitted model to predict if the documents in test data are spam or not\n",
        "docs_test = [\n",
        "             \"lottery winner\",\n",
        "             \"hello foo\", \n",
        "             \"hello bar\", \n",
        "             \"lottery prize\", \n",
        "             \"world foo\",\n",
        "             \"prize winner\",\n",
        "            ]\n",
        "X_test = vectorizer.transform(docs_test).toarray()\n",
        "predictions = []\n",
        "print(f'Spam classification (1 means document is spam):\\n====\\n{predictions}\\n====\\n')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features: ['bar', 'foo', 'hello', 'lottery', 'prize', 'winner', 'world']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-fbaa4e590231>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m '''\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#TBD Fit the model to training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m '''\n\u001b[1;32m     44\u001b[0m     \u001b[0mTest\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1527\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2400, 204]"
          ]
        }
      ]
    }
  ]
}